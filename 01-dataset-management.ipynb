{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d4c0f5",
   "metadata": {},
   "source": [
    "# 01 - Dataset management\n",
    "\n",
    "The [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) is a popular dataset for recommender systems and is used in academic publications. The dataset contains 25M movie ratings for 62,000 movies given by 162,000 users. Many projects use only the user/item/rating information of MovieLens, but the original dataset provides metadata for the movies, as well. For example, which genres a movie has. Although we may not improve state-of-the-art results with our neural network architecture in this example, we will use the metadata to show how to multi-hot encode the categorical features.\n",
    "\n",
    "This notebook covers the following steps:\n",
    "1. Copy the `movielens` dataset to Cloud Storage\n",
    "2. Create Vertex AI Dataset resouces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7a890",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import cudf \n",
    "import pandas as pd\n",
    "import tensorflow.io as tf_io\n",
    "# from nvtabular.utils import download_file\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'merlin-on-gcp'\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'merlin-on-gcp'\n",
    "\n",
    "WORKSPACE = f\"gs://{BUCKET}/movielens25m\"\n",
    "\n",
    "MOVIES_DATASET_DISPLAY_NAME = 'movielens25m-movies'\n",
    "RATINGS_DATASET_DISPLAY_NAME = 'movielens25m-ratings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69667470",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_WORKSPACE = True\n",
    "\n",
    "if CLEAN_WORKSPACE and tf_io.gfile.exists(WORKSPACE):\n",
    "    print(\"Cleaning up the workspace...\")\n",
    "    tf_io.gfile.rmtree(WORKSPACE)\n",
    "\n",
    "if not tf_io.gfile.exists(WORKSPACE):\n",
    "    print(\"Creating a new workspace...\")\n",
    "    tf_io.gfile.mkdir(WORKSPACE)\n",
    "\n",
    "print(\"Workspace is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ea945",
   "metadata": {},
   "source": [
    "## 1. Copy the Dataset to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf26a9",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d429f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_file(\n",
    "#     \"http://files.grouplens.org/datasets/movielens/ml-25m.zip\",\n",
    "#     \"ml-25m.zip\"\n",
    "# )\n",
    "\n",
    "urlretrieve(\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-25m.zip\", \n",
    "    \"ml-25m.zip\")\n",
    "\n",
    "ZipFile(\"ml-25m.zip\", \"r\").extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029eb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ml-25m.zip\n",
    "!ls ml-25m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c992aa",
   "metadata": {},
   "source": [
    "### Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570066f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time movies = cudf.read_csv(\"ml-25m/movies.csv\")\n",
    "movies = pd.read_csv(\"ml-25m/movies.csv\")\n",
    "print(f\"Number of movies: {len(movies.index)}\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time ratings = cudf.read_csv(\"ml-25m/ratings.csv\")\n",
    "ratings = pd.read_csv(\"ml-25m/ratings.csv\")\n",
    "print(f\"Number of ratings: {len(ratings.index)}\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9edda2",
   "metadata": {},
   "source": [
    "### Upload CSV data files to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIES_GCS_LOCATION = os.path.join(WORKSPACE, \"dataset\", \"movies.csv\")\n",
    "RATINGS_GCS_LOCATION = os.path.join(WORKSPACE, \"dataset\", \"ratings.csv\")\n",
    "\n",
    "!gsutil cp ml-25m/movies.csv {MOVIES_GCS_LOCATION}\n",
    "!gsutil cp ml-25m/ratings.csv {RATINGS_GCS_LOCATION}\n",
    "!rm -r ml-25m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c224a",
   "metadata": {},
   "source": [
    "## 2. Create Vertex AI Dataset Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "     staging_bucket=BUCKET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747eda2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.TabularDataset.create(\n",
    "    display_name=MOVIES_DATASET_DISPLAY_NAME, gcs_source=MOVIES_GCS_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.TabularDataset.create(\n",
    "    display_name=RATINGS_DATASET_DISPLAY_NAME, gcs_source=RATINGS_GCS_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44922f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_datasets = vertex_ai.TabularDataset.list()\n",
    "for vertex_dataset in vertex_datasets:\n",
    "    print(\"Dataset display name:\", vertex_dataset.display_name)\n",
    "    print(\"Dataset gcs location\",  vertex_dataset.gca_resource.metadata['inputConfig']['gcsSource']['uri'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50124e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m73"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
